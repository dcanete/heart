---
title: 'Práctica 2: ¿Cómo realizar la limpieza y análisis de datos?'
author: "Balpreet Kaur Singh/Daniel Cañete Román"
tuthor: "María Isabel Guitart Hormigo"
date: '`r format(Sys.Date(),"%e de %B %Y")`'
output:
  html_document:
    toc: yes
#    number_sections: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Planificación

Trabajamos por GIT.

**Antes 28/5**. Reunión 17:00: Dani prepara rdm con esquema y notas de qué hacer en cada apartado.

**Desde reunión hasta 2/6.** Balpreet rellena el rmd con notas, avanzando sobretodo en el código fuente. Reunión sincro 17:00 -\> No celebrada

**Desde reunión hasta 4/6**. Dani revisa textos y avances de Bapreet, incluyendo propuestas de cambio. Reunión sincro 17:00

**Desde reunión hasta 7/6**. Balpreet rellena el rmd con notas, avanzando sobretodo en el código fuente. En la reunión debemos planificar la grabación del vídeo. Reunión sincro 17:00

**Desde reunión hasta 8/6**. Dani hace un repaso dejando cerrado el rdm. Genera html, prepara carpetas, ...

**12-16/6**. (pendiente de planificar) Grabación de vídeo.

Nota: hay mucho código que se puede utilizar de ejemplo: <https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset/code?datasetId=1226038&sortBy=voteCount&language=R>

Nota2: Hay pasos muy similares a la asignatura de minería de datos. He compartido mis PEC del semestre pasado.

# 0. Introdución y pasos iniciales

Esta práctica se ha realizado bajo el contexto de la asignatura **Tipología y ciclo de vida de los datos**, perteneciente al Máster en Ciencia de Datos de la Universitat Oberta de Catalunya. En ella, se aplican técnicas de **limpieza y análisis de datos** mediante el lenguaje de programación R.

Para facilitar la lectura se incorpora parte del enunciado utilizando el formato blockquote

Tras analizar el dataset resultante en la PRA1, se ha seleccionado el propuesto en el enunciado por tener mayor riqueza a nivel educativo.

Antes de empezar con los apartados propuestos en el enunciado de la PRA, se realizan pasos previos necesarios: carga de datos y librerías utilizadas:

```{r load_libraries, include=FALSE}
# Librerías que se utilizan en el código
if(!require('gt')) {install.packages('gt'); library('gt')}
if(!require("corrplot")) install.packages("corrplot"); library("corrplot")
if(!require("dplyr")) install.packages("dplyr"); library("dplyr") 
if(!require("ggplot2")) install.packages("ggplot2"); library("ggplot2")
if(!require("ggpubr")) install.packages("ggpubr"); library("ggpubr")
if(!require("gridExtra")) install.packages("gridExtra"); library("gridExtra")

# Cargamos los datos
ds<-read.csv("../data/heart.csv")
```

# 1. Descripción del dataset

> ¿Por qué es importante y qué pregunta/problema pretende responder?

En primer lugar, se estudia la documentación disponible en <https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset> donde se puede apreciar:

-   Se trata de un estudio ataques al corazon donde existen datos de de problemas de corazón donde se

-   Licencia [CC0: Public Domain](https://creativecommons.org/publicdomain/zero/1.0/). Sin copyright, lo cual nos habilita a utilizarlo sin problemas.

-   El dataset tiene las siguientes columnas:

    -   Age: Edad del paciente

    -   Sex : Sexo del paciente

    -   exang: angina inducida por el ejercicio (1 = sí; 0 = no)

    -   ca: número de venas principales

    -   cp : Tipo de dolor torácico

        -   Valor 1: angina típica

        -   Valor 2: angina atípica

        -   Valor 3: dolor no anginoso

        -   Valor 4: asintomático

    -   trtbps: presión arterial en reposo (en mm Hg)

    -   chol: colesterol en mg/dl obtenido a través del sensor BMI

    -   fbs: azúcar en sangre en ayunas \> 120 mg/dl (1 = verdadero; 0 = falso)

    -   rest_ecg : resultados electrocardiográficos en reposo

        -   Valor 0: normal

        -   Valor 1: tener anomalías en la onda ST-T (inversiones de la onda T y/o elevación o depresión del ST \> 0,05 mV)

        -   Valor 2: mostrar hipertrofia ventricular izquierda probable o definitiva según los criterios de Estes

    -   thalach: frecuencia cardíaca máxima alcanzada

    -   target: 0= menos posibilidades de ataque al corazón 1= más posibilidades de ataque al corazón

Corroboremos estos datos e indaguemos un poco más:

```{r}
head(ds) %>% gt()
summary (ds)
str(ds)
print ("Valores ausentes:")
colSums(is.na(ds))
print("Cadenas vacías")
colSums(ds=="")
print (paste (nrow(ds) , " observaciones")) 
print ("Valores diferentes de cp: ")
unique (ds$cp)
print ("Valores diferentes de restecg: ")
unique (ds$restecg)
print ("Valores diferentes de slp: ")
unique (ds$slp)
print ("Valores diferentes de caa: ")
unique (ds$caa)
print ("Valores diferentes de thall: ")
unique (ds$thall)
print ("Valores diferentes de sex: ")
unique (ds$sex)
print ("Valores diferentes de fbs: ")
unique (ds$fbs)
print ("Valores diferentes de exng: ")
unique (ds$exng)

```

Hay 303 observaciones, inicialmente no hay valores ausentes. Respecto los 0, estos son valores aceptables entre los valores disponibles de atributo. Es decir, los valores "0" no significan ausencia de valor para el atributo especifico.

Los campos no son exactamente como aparece en la documentación, pero se puede encontrar una descripción más actualizada en <https://www.kaggle.com/code/namanmanchanda/heart-attack-eda-prediction-90-accuracy>:

+------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+
| Campo      | Descripción                                                                                                            | Tipo                                              |
+============+========================================================================================================================+===================================================+
| age        | Edad del paciente                                                                                                      | int (29-77)                                       |
+------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+
| sex        | Sexo del paciente                                                                                                      | int (0 ó 1). No se indica qué significa cada cuál |
+------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+
| cp         | Tipo de dolor torácico                                                                                                 | int (0, 1, 2 ó 3)                                 |
|            |                                                                                                                        |                                                   |
|            | -   Valor 1: angina típica                                                                                             |                                                   |
|            |                                                                                                                        |                                                   |
|            | -   Valor 2: angina atípica                                                                                            |                                                   |
|            |                                                                                                                        |                                                   |
|            | -   Valor 3: dolor no anginoso                                                                                         |                                                   |
|            |                                                                                                                        |                                                   |
|            | -   Valor 4: asintomático                                                                                              |                                                   |
+------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+
| trtbps     | Presión arterial en reposo (en mm Hg)                                                                                  | int (94-200)                                      |
+------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+
| chol       | Colesterol en mg/dl obtenido a través del sensor BMI                                                                   | int (126-564)                                     |
+------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+
| fbs        | Azúcar en sangre en ayunas \> 120 mg/dl (1 = verdadero; 0 = falso)                                                     | int (0 ó 1)                                       |
+------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+
| restecg    | Electrocardiograma en reposo                                                                                           | int (0, 1 ó 2)                                    |
|            |                                                                                                                        |                                                   |
|            | -   Valor 0: normal                                                                                                    |                                                   |
|            |                                                                                                                        |                                                   |
|            | -   Valor 1: tener anomalías en la onda ST-T (inversiones de la onda T y/o elevación o depresión del ST \> 0,05 mV)    |                                                   |
|            |                                                                                                                        |                                                   |
|            | -   Valor 2: mostrar hipertrofia ventricular izquierda probable o definitiva según los criterios de Estes              |                                                   |
+------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+
| thalachh   | Frecuencia cardíaca máxima alcanzada                                                                                   | int (71-202)                                      |
+------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+
| exng       | Angina inducida por el ejercicio (1 = sí; 0 = no)                                                                      | int (0 ó 1)                                       |
+------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+
| oldpeak    | Pico anterior                                                                                                          | num (0-6.2)                                       |
+------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+
| slp        | Tendencia. Es una codificación, pero **no se conoce el significado** de cada valor.                                    | int (0, 1 ó 2)                                    |
+------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+
| caa        | Número de venas principales                                                                                            | int (0, 1, 2, 3 ó 4)                              |
+------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+
| thall      | Resultado de la prueba de esfuerzo con talio. Es una codificación, pero **no se conoce el significado** de cada valor. | int (0, 1, 2 ó 3)                                 |
+------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+
| output     | Variable objetivo. Es una codificación, no se conoce el significado de cada valor. Supuesto:                           | int (0 ó 1)                                       |
|            |                                                                                                                        |                                                   |
|            | -   0, no predispuesto                                                                                                 |                                                   |
|            |                                                                                                                        |                                                   |
|            | -   1, predispuesto                                                                                                    |                                                   |
+------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+

Vemos que tenemos:

-   Una variable objetivo categórica: output

-   Variables categóricas: sex, cp, fbs, restecg, exng, slp, caa y thall

-   Variables numéricas: age, trtbps, chol, thalachh y oldpeak

**¿Por qué es importante y qué pregunta/problema pretende responder?**

Ahora conocemos un poco mejor los datos, podemos responder a la pregunta. Se trata de un dataset con información clínica de pacientes que están predispuestos o no a tener una angina de pecho. Evidentemente es muy interesante para crear un modelo predictivo, pero también para conocer qué variables hacen que una persona tenga más posibilidades de padecer una angina de pecho.

**Nota**: Hay algunos campos que no conocemos su significado concreto, pero aún así se pueden utilizar para el modelo. Si se detectan que son variables relacionadas con la variable objetivo, un experto puede describir su significado.

# 2. Integración y selección

> Integración y selección de los datos de interés a analizar. Puede ser el resultado de adicionar diferentes datasets o una subselección útil de los datos originales, en base al objetivo que se quiera conseguir.

La muestra no tiene un número elevado de registros que puedan dar problemas en el rendimiento. En caso de que si la hubiera, habría que ver alguna manera de limitar los datos, al menos para facilitar los cálculos en fase de desarrollo.

Organizamos y buscamos duplicados:

```{r}
# Cambio de tipo variables clasificatorias
ds$sex <- as.factor(ds$sex)
ds$cp <- as.factor(ds$cp)
ds$fbs <- as.factor(ds$fbs)
ds$restecg <- as.factor(ds$restecg)
ds$exng <- as.factor(ds$exng)
ds$slp <- as.factor(ds$slp)
ds$caa <- as.factor(ds$caa)
ds$thall <- as.factor(ds$thall)
ds$output <- as.factor(ds$output)

# Cambio de variables numericas
ds$age <- as.numeric (ds$age)
ds$trtbps <- as.numeric (ds$trtbps)
ds$chol <- as.numeric (ds$chol)
ds$thalachh <- as.numeric (ds$thalachh)
ds$oldpeak <- as.numeric (ds$oldpeak)

# Ordenación de los campos (objetivo, clasificatorias y numéricas)
ds <- ds [, c ("output", "sex", "cp", "fbs", "restecg", "exng", "slp", "caa", "thall", "age", "trtbps", "chol", "thalachh", "oldpeak")]

# Búsqueda de duplicados
print(paste ("Numero de Rows Duplicados:", nrow(ds[duplicated(ds), ]), "duplicados"))

<<<<<<< HEAD
# Eliminamos duplicados
=======

```{r}

#comprobamos y quitemos los duplicados:
print("Numero de Rows Duplicados:")
nrow(ds[duplicated(ds), ])

#Quitar row duplicados:
>>>>>>> ef8b8bc834e6a053c421d8032c68dee78d617056
ds<-ds[!duplicated(ds), ]
print(paste ("Comprobacion de Rows No Duplicados:", nrow(ds[duplicated(ds), ]), "duplicados"))

```

<<<<<<< HEAD
Se ha detectado un duplicado donde se ha supuesto que ha habido una errata y se ha inscrito dos veces la misma observación. Se considera poco probable que haya dos observaciones exactamente iguales, pero en un caso real sería recomendable que lo valorase un experto.
=======
Hablando de duplicado de row, aqui suponemos que los datos de una misma observación ha sido repetida. Por tanto, eliminamos de nuestros datos. 

Pero también puede dar el caso en la realidad de que dos observaciones/personas tengan exactamente los mismos datos. En este caso, lo dejariamos en nuestro dataset. Pero ahora para esta práctica, eliminaremos este row repetido al entender que este row ha sido repetido erroneamente. 

>>>>>>> ef8b8bc834e6a053c421d8032c68dee78d617056

Vamos a estudiar un poco más los campos categóricos comparándolos con la variable objetivo:

```{r}
myHistCat <- function(campo) {
  myPlot <- ggplot(ds, aes(val, fill = output)) +
    geom_bar() + labs(x = campo, y = "Observaciones") +
    guides(fill = guide_legend(title = "")) +
    scale_fill_manual(values = c("black", "#008000")) +
    theme(axis.text.x = element_text(angle = 10, vjust = 1, hjust=0.5)) 
  return (myPlot)
}

grid.arrange(myHistCat("output"), myHistCat("sex"), myHistCat("cp"), 
             myHistCat("fbs"), myHistCat("restecg"), myHistCat("exng"), 
             myHistCat("slp"), myHistCat("caa"), myHistCat("thall"),
             ncol = 3, nrow = 3)

```

Sorprende que hay más personas predispuestas de las que no (164/138). Eso hace pensar que **la muestra está sesgada**, seguramente se ha obtenido entre pacientes que tenían alguna patología. Por eso se considera que **el estudio puede servir para detectar factores de riesgo, pero no se pueden sacar conclusiones a nivel de población general**,

Se observan también algunos valores posibles de variables con muy pocas observaciones, por lo que será difícil que sean significativos en un modelo predictivo. Este es el caso, por ejemplo:

-   4 venas principales en caa, donde hay solo 5 observaciones. De hecho, en la descripción no se contemplaba ese valor.

-   0 en la prueba de esfuerzo, donde hay solo dos observaciones.

-   2 en restecg (hipertrofia ventricular izquierda probable o definitiva según los criterios de Estes) donde solo hay 4 observaciones.

```{r}
for (i in 1:9) {
  vName <- names(ds)[i]
  print (vName)
  print (table(val, ds$output))
}
```

Viendo las tablas por cada variable, podemos observar lo siguiente:

-   sex: tenemos un total de 96 personas de sexo tipo "0" y 206 personas de sexo tipo "1". Y si pasamos a profundizar más en estos totales, podemos ver que tenemos 72 casos de los 96 que tienen ataque cardiaco. Y 92 casos de los 206 tienen ataque cardiaco.

<<<<<<< HEAD
-   cp: vemos que tenemos un total de 143 personas de cp tipo "0" (no padecen ningún tipo de Chest Pain listados), de los cuales 39 tienen ataque cardíaco. Después tenemos 50 personas de cp tipo "1" (los cuales padecen dolor típico de angina), entre los cuales 41 son personas que padecen ataque cardíaco. Tenemos 86 personas de sexo tipo "2" (los cuales padecen dolor no anginoso), entre los cuales 68 son personas que padecen ataque cardíaco. Y por último, de las 32 personas que padecen dolor de pecho son debido a dolores asintomático, solamente 16 padecen ataque cardíaco.
=======
- Visualizando la grafica y las cantidades numericas del sexo, vemos que tenemos un total de 96 personas de sexo tipo "0" y 206 personas de sexo tipo "1". Y si pasamos a profundizar más en estos totales, podemos ver que tenemos 72 casos de los 96 de Sexo "0" tienen ataque cardiaco.Y 92 casos de los 206 de Sexo "1" tienen ataque cardiaco.
>>>>>>> ef8b8bc834e6a053c421d8032c68dee78d617056

-   fbs: el cual significa fasting blood sugar (glucemia en ayunas), podemos decir que 54,86% (141/(116+141)) de las personas no padecen glucemia en ayunas tiene ataque cardíaco. En cambio, el porcentaje de tener el ataque cardíaco baja a 51,11% (23/(22+23)) para las personas que padecen glucemia en ayunas. Y sumando las 2 categorías, tenemos que la probabilidad de tener ataque cardíaco es 54,3% ((141+23)/(302)) independientemente de si la persona ha tenido glucemia en ayunas o no. Por tanto, en resumen, las personas que no padecen glucemia en ayunas tienen mas probabilidad de tener un ataque cardíaco.

-   restecg: el cual significa resultados electrocardiográficos en reposo, podemos decir que 46,25% (68/(68+79)) de las personas que tienen un resultado electrocardiográficos en reposo NORMAL pueden padecer un ataque cardíaco. Y este porcentaje sube a 62,91% en el caso de personas con anomalía en la onda ST-T. Y es 25% la probabilidad de que una persona que muestra hipertrofia ventricular izquierda probable o definitiva según los criterios de Estes padezca un ataque cardíaco. Y sumando ((68+95+1)/(79+68+56+95+3+1)), como esperamos, hay una probabilidad de 54,3% de que una persona padezca un ataque cardíaco independientemente de tipo de resultados electrocardiográficos en reposo. En resumen, hay más probabilidad de que una persona con anomalía en la onda ST-T padezca un ataque cardíaco comparado a las 2 otros tipos de resultados electrocardiográficos en reposo. Y podemos decir de que es mas probable de una una persona con resultado NORMAL padezca un ataque cardíaco que una persona que muestre hipertrofia ventricular izquierda probable o definitiva según los criterios de Estes.

-   exng: que significa angina inducida por el ejercicio (exercise induced angina), podemos decir 69,45% de los casos de personas de tener angina no inducida por el ejercicio tienen ataque cardíaco. En cambio, si hablamos de personas con angina inducida por el ejercicio, este porcentaje de padecer el ataque cardíaco baja a 23%. Claramente analizamos que las personas con angina no inducida por el ejercicio es mas que doble de probable que la persona con angina inducida por ejercicio.

-   slp: podemos observar que las personas que cubran el "slope" tipo 0 tienen una probabilidad de 42,85% de sufrir el ataque cardíaco y las personas que cubren slope tipo "1" tiene una probabilidad de padecer el ataque cardíaco en un 35%. Las personas de slope tipo "2" tienen una probabilidad de 75,17% de tener el ataque cardíaco. Por tanto, Slope tipo "2" tiene más probabilidad de tener el ataque cardíaco en comparación a los otros 2 tipos y el slope tipo "1" es la que menos probabilidad.

-   caa: podemos decir que 74,28% para personas con 0 venas principales (major vessels) tienen ataque cardiaco, 32,3% para personas con 1 vena principal, 18,42% para personas con 2 venas principales, 15% para personas con 3 venas principales y 75% para personas con 4 venas principales.

-   thall: tenemos que hay 50% probable de que una persona con Thalium Stress Test result "0" padezca un ataque cardiaco, 33,33% para personas con resultado "1" de prueba de Thalium Stress, 78,18% para personas con resultado "2" de prueba de Thalium Stress y 23,93% para personas con resultado "3" de prueba de Thalium Stress.

Estudiemos los valores numéricos:

```{r}
myHistNum <- function(campo) {
  myPlot <- ggplot(ds, aes(x=ds[,campo])) + geom_histogram() +
    labs(x = campo)
  return (myPlot)
}

grid.arrange(myHistNum("age"), myHistNum("trtbps"), myHistNum("chol"), 
             myHistNum(""), myHistNum(""), myHistNum(""),
             ncol = 3, nrow = 3)

myHistNum ("age")

ds$age <- as.numeric (ds$age)
ds$trtbps <- as.numeric (ds$trtbps)
ds$chol <- as.numeric (ds$chol)
ds$thalachh <- as.numeric (ds$thalachh)
ds$oldpeak <- as.numeric (ds$oldpeak)

myCaja <- function(campo) {
  myPlot <- ggplot(ds, aes(val, fill = output)) +
    geom_bar() + labs(x = campo, y = "Observaciones") +
    guides(fill = guide_legend(title = "")) +
    scale_fill_manual(values = c("black", "#008000")) +
    theme(axis.text.x = element_text(angle = 10, vjust = 1, hjust=0.5)) 
  return (myPlot)
}

grid.arrange(myHist1("output"), myHist1("sex"), myHist1("cp"), 
             myHist1("fbs"), myHist1("restecg"), myHist1("exng"), 
             myHist1("slp"), myHist1("caa"), myHist1("thall"),
             ncol = 3, nrow = 3)

myHist1 (chol)

ds["sex"]

plotList<- list(5)
plotList2<- list(5)

for(i in 10:14){
  col_names <- names(ds)[i]
  col_val <- ds[,i]
  p <- ggplot(ds, aes(x=output, y=col_val, fill=output)) +
    geom_boxplot(alpha=0.5) +
    labs(x = "output", y = col_names) +
    theme(legend.position="none") 
  plotList[[i-9]] <- p
  p <- ggplot(ds, aes(x=col_val)) + geom_histogram() +
    labs(x = col_names)
  plotList2[[i-9]] <- p
  print (ggplot(ds, aes(x=col_val)) + geom_histogram() +
    labs(x = col_names))
}

kk1 <- ggplot(ds, aes(x=output, y=ds[,10], fill=output)) +
    geom_boxplot(alpha=0.5) +
    labs(x = "output", y = names(ds)[10]) +
    theme(legend.position="none") 
kk2 <- ggplot(ds, aes(x=output, y=ds[,11], fill=output)) +
    geom_boxplot(alpha=0.5) +
    labs(x = "output", y = names(ds)[11]) +
    theme(legend.position="none") 
plotList <- list(kk1, kk2) 

do.call("grid.arrange", c(plotList, ncol = 3))
do.call("grid.arrange", c(plotList2, ncol = 3))     

plotList[1]
plotList[2]

```

Al analizar las distribuciones en las histogramas sin tener en cuenta los boxplots, podemos decir que las observaciones son mas frecuentes cuando:

-   Picos anteriores (oldpeak) son más cercano a 0

-   Frecuencia cardiaca (thalachh) con valores superiores a 140 y inferiores a 180.

-   Presión arterial en reposo está entre 100 y 160 Hg.

-   Colesterol esta entre 150 y 350 mg/dl segun BMI sensor

-   Y edad entre 40 y 70 años.

Pero al analizar los diagramas de cajas segun la variable objetivo, ya se pueden intuir alguna conclusión de correlacion. Por ejemplo, parece que es más probable tener ataque al corazón (output = 1) cuando:

-   Picos anteriores (oldpeak) son más cercano a 0

-   Frecuencia cardiaca (thalachh) con valores entre 150y 170.

-   Presión arterial en reposo está entre 100 y 140 Hg.

-   Colesterol esta entre 205 y 265 mg/dl segun BMI sensor

-   Y edad entre 45 y 59 años.

Estudiemos la correlación entre las variables. Si encontramos alguna muy relacionadas podemos quitarlas del modelo y reducir su complejidad:

```{r}
n = c("age", "trtbps", "chol", "thalachh", "oldpeak")
factores= ds %>% select(all_of(n))
res<-cor(factores)
corrplot(res,method="color",tl.col="black", tl.srt=30, order = "AOE",
number.cex=0.75,sig.level = 0.01, addCoef.col = "black")

matriz <- cor (ds[,n])
corrplot(matriz, type="upper", order="hclust", tl.col="black", tl.srt=45)

```

Observamos que no hay una alta correlación entre las variables por lo que no prescindiremos de ninguna.

```{r}
# o2_saturation <- read.csv("../data//o2Saturation.csv")
# o2_saturation.head()
# ds$o2_Saturation = o2_saturation$X98.6
# ha_df.head()
```

# 3. Limpieza de los datos

> 3.1. ¿Los datos contienen ceros o elementos vacíos? Gestiona cada uno de estos casos
>
> 3.2. Identifica y gestiona los valores extremos

En el punto anterior se ha analizado el dataset y observando los resultados, ya podemos obtener algunas conclusiones sin necesidad de desarrollar más código:

-   **No se aprecian valores ausentes**, muchas veces identificados por "na". A veces se identifican con '0', pero este valor, en nuestro caso, en la mayoría de las variables tiene un significado concreto y son recolectador y/o insertados sin transformación previa alguna. Asumiendo que los datos son recogidos sin errores alguno, podemos afirmar que no hay ausencia de valores. En el caso de que el "0" signifique ausencia de valores, en ese supuesto habría que transformar estos "0" con un valor mas ideoneo, por ejemplo la media o la mediana para la variable numerica y moda para la categorica.Pero para nuestro caso asumimos que no ha habido ningun error al recolectar estos datos ni se ha insertado "0" como sustituyente al dato faltante. Por tanto, estos valores son aceptados como uno de los valores listados para el atributo correspondiente.

-   En los diagramas de cajas, vemos varios valores fuera de los rangos normales. Estos son valores extremos que habría que consultar a un experto si es posible que fueran erróneos para descartarlos. Si sorprende mucho la **observación con colesterol mayor, que está muy separada de los rangos normales**, la cual estamos seguros de que es un dato erroneo. Por tanto, habria que estudiar todo los casos de valores extremos, los cuales se encuentra superiores al valor maximo y inferiores al valor minimo de la variable correspondiente. Y Asegurar que estos valores fuera del rango [minimo, maximo] no sean datos erroneos. En caso de que no fueran datos erroneas, debemos analizarlos con un experto en este campo para asegurar que estos valores son aceptables o no.

La gestión de valores atípicos (outlier management) es la ciencia de investigar y aplicar un tratamiento adecuado a los valores atípicos en los datos. Puede ser tentador simplemente eliminar los registros donde hay valores atípicos en el conjunto de datos, pero no siempre es el mejor enfoque. El método de tratamiento de valores atípicos puede variar de un caso a otro y debe discutirse con la empresa antes de finalizar el método. Existen diferentes enfoques, como reemplazar el valor atípico con el valor medio o el valor mediano o, en algunos casos, descartar la observación con el valor atípico sospechoso para evitar cualquier sesgo en ellos. Tendemos a eliminar los valores atípicos si se deben a errores de entrada de datos causados por errores humanos, errores de procesamiento de datos.

Vamos a gestionar el último valor extremo de Colestrol, del cual estamos seguros que es valor extremo inaceptable:

```{r}

#max(ds$chol,4)
ds %>%                                      # Top N highest values 
  arrange(desc(chol)) %>% 
  slice(1:8)
```

```{r}
max(ds$chol)
ds [ds$chol==max(ds$chol), ]

# El ultimo valor extremo de cholestrol lo sustituimos por la media al estar seguros de que es un valor outlier erroneo.
ds [ds$chol==max(ds$chol), ]$chol <- mean (ds$chol)
```

Obviamente, en un caso real, esta decisión debería tomarse junto con un experto que determine si realmente los demas valores extremos son un valores erroneos o no decidiendo si:

-   Se elimina de la muestra

-   Se ajusta su valor a la media u otra variable estadística

<<<<<<< HEAD
-   Se considera con valor ausente (Balpreet:?)
=======
-   Se considera con valor ausente de la columna  
>>>>>>> ef8b8bc834e6a053c421d8032c68dee78d617056

# 4. Análisis de los datos

`Pendiente: La solucion oficial de la PEC2 puede venir muy bien para esto. Sale el día 2/6`

## 4.1. Selección de los grupos de datos

> Selección de los grupos de datos que se quieren analizar/comparar (p. ej., si se van a comparar grupos de datos, ¿cuáles son estos grupos y qué tipo de análisis se van a aplicar?)

Teniendo en cuenta el output, procederemos a analizar los diferentes atributos respecto este output. Por tanto, procederemos a hacer los comparaciones entre siguientes grupos y siguientes test:

- Output y atributos categoricos ['sex', 'cp', 'fbs', 'restecg','exng','slp', 'caa', 'thall']: tenemos dos variables categóricas y haremos un test de χ2 para ver si existen diferencias significativas entre los grupos definidos. Pero en nuestro caso, tenemos una muestra pequeña, portanto, usaremos Fisher Test.

- Output y variables numericas nominal ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']: si cumple normalidad y homocedasticidad con output, aplicamos tStudent, si no, test de Mann-Whitney.


## 4.2. Comprobación de la normalidad y homogeneidad de la varianza.

Comprobamos la normalidad y homogeneidad de la varianza:

Testing normality assumption

```{r}
library(EnvStats)
ds$age %>% qqPlot(dist="norm", ylab = "Age")
```

```{r}
library(EnvStats)
ds$trtbps %>% qqPlot(dist="norm", ylab = "trtbps")
```
```{r}
library(EnvStats)
ds$chol %>% qqPlot(dist="norm", ylab = "chol")
```
```{r}
library(EnvStats)
ds$thalachh %>% qqPlot(dist="norm", ylab = "thalachh")
```

```{r}
library(EnvStats)
ds$chol %>% qqPlot(dist="norm", ylab = "oldpeak")
```
```{r}
shapiro.test(ds$age)
```
El valor P es inferior a 0,05, lo que significa que los datos de edad no se distribuyen normalmente.

```{r}
shapiro.test(ds$trtbps)
```

Los datos trtbps no se distribuyen normalmente.

```{r}
shapiro.test(ds$chol)
```

Los datos chol no se distribuyen normalmente.


```{r}
shapiro.test(ds$thalachh)
```
Los datos de thalachh no se distribuyen normalmente.

```{r}
shapiro.test(ds$oldpeak)
```
Los datos del pico anterior no se distribuyen normalmente.


Podemos ver que no tenemos normalidad en nuestros datos numéricos.

Ahora veamos homogeneidad de varianza mediante Levene Test (no FTest) ya que no cumplimos el requisito de normalidad:

```{r}
leveneTest(age ~ output, data = ds)
```

El valor p es 0.006079 es más bajo que el nivel de significancia de 0.05. Podemos concluir que existe una diferencia significativa entre las varianzas de la muestra probada.

```{r}
leveneTest(trtbps ~ output, data = ds)
```

El valor p es 0.1818 es mayor que el nivel de significancia de 0.05. Podemos concluir que no hay una diferencia significativa entre las varianzas de la muestra probada.

```{r}
leveneTest(chol ~ output, data = ds)
```

El valor p es 0.7264 es mayor que el nivel de significancia de 0.05. Podemos concluir que no hay una diferencia significativa entre las varianzas de la muestra probada.

```{r}
leveneTest(thalachh ~ output, data = ds)
```
El valor p es 0.02374 es más bajo que el nivel de significancia de 0.05. Podemos concluir que existe una diferencia significativa entre las varianzas de la muestra probada.

```{r}
leveneTest(oldpeak ~ output, data = ds)
```
El valor p es inferior al nivel de significación de 0,05. Podemos concluir que existe una diferencia significativa entre las varianzas de la muestra probada.

Por tanto, incumplimos la asumpciones de que el dataset sea normal y tenga homogeneidad de varianza.


## 4.3. Aplicación de pruebas estadísticas para comparar los grupos de datos.

> En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes. 

Primero haremos Fisher Test para analizar la independencia de los grupos de datos:

La prueba exacta de Fisher determinará si existe una relación estadísticamente significativa entre 2 atributos categóricos.

Nulo (H0): No existe asociación entre ambos atributos categóricos. son independientes
Alternativa (HA): Existe una relación entre ellos en la población.

Además, la prueba de Fisher es una prueba estadística que se utiliza para determinar si las proporciones de las categorías en dos variables de grupo difieren significativamente entre sí.

```{r}
counts <- table(ds$output, ds$sex)
counts / rowSums(counts) 
```

Podemos ver que el 43,9% de sexo "0" tuvieron heart attack, por debajo del sexo "1" con probabilidad de 56,09% . Es sorprendente esta diferencia. Pero para salir de la duda, necesitamos una prueba estadística. La prueba de chi-cuadrado se puede utilizar para probar la correlación de dos variables categóricas. Pero usaremos Fisher test porque nuestro dataset no es suficientemente grande (<1000) como para aplicar Chi-cuadrado.


```{r}
fisher.test(counts)
```

Cuando su valor p esté por debajo de su nivel de significación (p. ej., 0,05), rechace la hipótesis nula. Los datos de la muestra son lo suficientemente fuertes como para concluir que existe una relación entre las variables categóricas en la población. Conocer el valor de una variable proporciona información sobre el valor de la otra variable.

Por otro lado, La hipótesis nula es que hombres y mujeres tienen la misma probabilidad de tener un heart attack. El valor p es bajo. Por tanto, rechazamos la hipótesis de que ambos sexos tienen la misma tasa de sufrir un infarto. Mirando los datos, es más alto para el tipo de sexo "1".

Haremos lo mismo con otros atributos:

```{r}
counts <- table(ds$output, ds$cp)
counts / rowSums(counts) 
```

```{r}
fisher.test(counts)
```

Lo mismo aqui, rechazamos la hipotesis nula y confirmamos de que la probabilidad de tener un ataque es más alto en cp=2 teniendo en consideración la grafica y estadisticas anteriores.

Cuando su valor p esté por debajo de su nivel de significación (p. ej., 0,05), rechace la hipótesis nula. Los datos de la muestra son lo suficientemente fuertes como para concluir que existe una relación entre las variables categóricas en la población. Conocer el valor de una variable proporciona información sobre el valor de la otra variable.

```{r}
counts <- table(ds$output, ds$fbs)
counts / rowSums(counts) 
```

```{r}
fisher.test(counts)
```
No rechazamos la Ho  y, por tanto, los diferentes tipos de cps tienen mas o menos la misma probabilidad de tener un ataque infarto.

Cuando su valor p esté por debajo de su nivel de significación (p. ej., 0,05), rechaza la hipótesis nula. Los datos de la muestra son lo suficientemente fuertes como para concluir que existe una relación entre las variables categóricas en la población. Conocer el valor de una variable proporciona información sobre el valor de la otra variable.

```{r}
counts <- table(ds$output, ds$restecg)
counts / rowSums(counts) 
```

```{r}
fisher.test(counts)
```
Lo mismo aqui, rechazamos la hipotesis nula y confirmamos de que la probabilidad de tener un ataque es más alto en restecg=1 teniendo en cuenta la grafica y estadisticas anteriores.

Cuando su valor p esté por debajo de su nivel de significación (p. ej., 0,05), rechaza la hipótesis nula. Los datos de la muestra son lo suficientemente fuertes como para concluir que existe una relación entre las variables categóricas en la población. Conocer el valor de una variable proporciona información sobre el valor de la otra variable.

```{r}
counts <- table(ds$output, ds$exng)
counts / rowSums(counts) 
```

```{r}
fisher.test(counts)
```

Lo mismo aqui, rechazamos la hipotesis nula y confirmamos de que la probabilidad de tener un ataque es más alto en exng=0 teniendo en cuenta la grafica y las estadisticas anteriores.

Cuando su valor p esté por debajo de su nivel de significación (p. ej., 0,05), rechaza la hipótesis nula. Los datos de la muestra son lo suficientemente fuertes como para concluir que existe una relación entre las variables categóricas en la población. Conocer el valor de una variable proporciona información sobre el valor de la otra variable.

```{r}
counts <- table(ds$output, ds$slp)
counts / rowSums(counts) 
```

```{r}
fisher.test(counts)
```
Lo mismo aqui, rechazamos la hipotesis nula y confirmamos de que la probabilidad de tener un ataque es más alto en slp=2 teniendo en cuenta la grafica y las estadisticas anteriores.

Cuando su valor p esté por debajo de su nivel de significación (p. ej., 0,05), rechaza la hipótesis nula. Los datos de la muestra son lo suficientemente fuertes como para concluir que existe una relación entre las variables categóricas en la población. Conocer el valor de una variable proporciona información sobre el valor de la otra variable.


```{r}
counts <- table(ds$output, ds$caa)
counts / rowSums(counts) 
```
```{r}
fisher.test(counts)
```


Lo mismo aqui, rechazamos la hipotesis nula y confirmamos de que la probabilidad de tener un ataque es más alto en caa=0 teniendo en cuenta la grafica y las estadisticas anteriores.

Cuando su valor p esté por debajo de su nivel de significación (p. ej., 0,05), rechaza la hipótesis nula. Los datos de la muestra son lo suficientemente fuertes como para concluir que existe una relación entre las variables categóricas en la población. Conocer el valor de una variable proporciona información sobre el valor de la otra variable.


```{r}
counts <- table(ds$output, ds$thall)
counts / rowSums(counts) 
fisher.test(counts)
```

Lo mismo aqui, rechazamos la hipotesis nula y confirmamos de que la probabilidad de tener un ataque es más alto en thall=2 teniendo en cuenta la grafica y las estadisticas anteriores.

Cuando su valor p esté por debajo de su nivel de significación (p. ej., 0,05), rechaza la hipótesis nula. Los datos de la muestra son lo suficientemente fuertes como para concluir que existe una relación entre las variables categóricas en la población. Conocer el valor de una variable proporciona información sobre el valor de la otra variable.

```{r}
counts <- table(ds$output, ds$output)
counts / rowSums(counts) 
fisher.test(counts)
```
Aqui podemos rechazar la hipotesis nula de que las medias entre los 2 outputs son iguales y decir que hay mas probabilidad de que una persona tenga ataque de corazon según las graficas y estadisticas anteriores.

Cuando su valor p esté por debajo de su nivel de significación (p. ej., 0,05), rechaza la hipótesis nula. Los datos de la muestra son lo suficientemente fuertes como para concluir que existe una relación entre las variables categóricas en la población. Conocer el valor de una variable proporciona información sobre el valor de la otra variable.

---
Ahora vamos a estudiar los atributos numericos versus el output mediante  mediante Whitney.

```{r}
str(ds[10:14])
```

```{r}
wilcox.test(age ~ output, data=ds) 
```
 

```{r}
wilcox.test(trtbps ~ output, data=ds) 
```


```{r}
wilcox.test(chol ~ output, data=ds) 
```


```{r}
wilcox.test(thalachh ~ output, data=ds) 
```


```{r}
wilcox.test(oldpeak ~ output, data=ds) 
```
Con un nivel de significancia de .05, rechazamos Hº y podemos concluir que todos los atributos numéricos y la salida en el conjunto de datos provienen de poblaciones no idénticas. Podemos concluir que la diferencia entre la mediana de la población de salida y el atributo numérico correspondiente es estadísticamente significativa.


```{r}
install.packages("ggcorrplot")
library(ggcorrplot)
numerical_data <- ds[10:14]
data_normalized <- scale(numerical_data)
corr_matrix <- cor(data_normalized)
ggcorrplot(corr_matrix)
```


```{r}
data.pca <- princomp(corr_matrix)
summary(data.pca)
```

Los resultados anteriores muestran cuán importantes son estos 4 componentes de PCA considerando lo siguiente:

- El componente 1 explica el 57,70% de la varianza total.
- El componente 2 explica el 18,87% de la varianza total.
- El componente 3 explica el 14,56% de la varianza total.
- El componente 4 explica el 8,56% de la varianza total.

Extra: es genial tener los primeros 4 componentes, pero ¿qué significan realmente? Esto se puede responder explorando cómo se relacionan con cada columna utilizando las cargas de cada componente principal. 


```{r}
data.pca$loadings[, 1:4]
```
¿Cómo interpretamos estos resultados? Por ejemplo, centrándonos en el Componente 1, debemos mencionar que el atributo "thalachh" impacta negativamente en el PCA y los otros factores de forma positiva. Y el mismo enfoque se aplica a los otros componentes.

# 5. Representación de los resultados

> Representación de los resultados a partir de tablas y gráficas. Este apartado se puede responder a lo largo de la práctica, sin necesidad de concentrar todas las representaciones en este punto de la práctica.

En el desarrollo del ejercicio se han ido utilizando diagramas representativos. Para seleccionar los más interesantes en cada caso, se ha utilizado como referencia la siguiente url: <https://www.data-to-viz.com/>

# 6. Resolución del problema

> A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?

Based on the results given above, we have the following conclusions:

- Tenemos más probabilidad de tener un caso de ataque cardiaco.
- Sexo 0 tiene más probabilidad de tener un ataque cardiaco.
- Cp tipo 2 tiende a tener más probabilidad de ataque cardiaco.

- Fbs con anomalía en la onda ST-T tiene 62% de probabilidad de tener el ataque cardiaco.

- Respecto variable angina inducida por el ejercicio (exng), podemos decir 69,45% de los casos de personas de tener angina no inducida por el ejercicio tienen ataque cardiaco. Este baja a 23% cuando el ataque cardiaco es debido a angina inducida por el ejercicio.

- Slope tipo "2" tiene más probabilidad de tener el ataque cardiaco.

- Respecto la caa, personas con 0 venas principales tienen más probabilidad de tener el ataque cardiaco.

- Respecto thall, decir que personas con resultado "2" de prueba de Thalium Stress tiene una probabilidad de 78,18% de tener el ataque cardiaco.

Y es más probable tener ataque al corazón (output = 1) cuando:

-   Picos anteriores (oldpeak) son más cercano a 0

-   Frecuencia cardiaca (thalachh) con valores entre 150y 170.
-  Presión arterial en reposo está entre 100 y 140 Hg.
-  Colesterol esta entre 205 y 265 mg/dl  segun BMI sensor
- Y edad entre 45 y 59 años.

Despues de comprobar qqtest, shapiro test y levene test comprobamos que incumplimos la asumpciones de que el dataset sea normal y tenga homogeneidad de varianza.

Despues de hacer Fisher Test, pudimos comprobar que los datos de la muestra son lo suficientemente fuertes como para concluir que existe una relación entre las variables categóricas en la población. Y Conocer el valor de una variable proporciona información sobre el valor de la otra variable.


Respecto las variables numericas y mediante el Whitney Test, pudimos comprobar que todos los atributos numéricos y la salida en el conjunto de datos provienen de poblaciones no idénticas. Podemos concluir que la diferencia entre la mediana de la población de salida y el atributo numérico correspondiente es estadísticamente significativa.



# 7. Código

> Hay que adjuntar el código, preferiblemente en R, con el que se ha realizado la limpieza, análisis y representación de los datos. Si lo preferís, también podéis trabajar en Python.

Disponible en este mismo fichero.

# 8. Vídeo

> Realizar un breve vídeo explicativo de la práctica (máximo 10 minutos), donde ambos integrantes del equipo expliquen con sus propias palabras el desarrollo de la práctica, basándose en las preguntas del enunciado para justificar y explicar el código desarrollado. Este vídeo se deberá entregar a través de un enlace al Google Drive de la UOC ([https://drive.google.com/...),](https://drive.google.com/…),) junto con enlace al repositorio Git entregado.

Se puede visualizar en cualquiera de estas dos alternativas:

-   Github: <https://github.com/dcanete/heart>

-   Drive: <https://drive.google.com/open?id=1gko9Vw2D3FQP5aewnnfp-hPio-AZ70KZ>


